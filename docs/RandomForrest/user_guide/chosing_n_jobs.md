# How to chose the n_jobs parameter of RandomForrest
When creating a forrest you can supply the parameter n_jobs[Link to parameter]. As stated in the documentation this controls the number of processes used when fitting and predicting the Random Forrest. Because we allow creation of one's own [criteria function](../../decision_tree/examples/creatingACriteria.md), and we do not want to require that the [GIL](https://wiki.python.org/moin/GlobalInterpreterLock) is released in these, it is not feasible to do multithreading. We have therefore implemented parallelism using python's [multiprocessing library](https://docs.python.org/3/library/multiprocessing.html).

The overhead involved in setting up each new process when doing multiprocessing is rather large. Thus there is a trade-off between the overhead introduced in setting up each new process versus the amount of work that each process gets to do. For a lower amount of trees or smaller datasets this often results in diminishing returns on the speedup gained from using more processors. Since the n_jobs parameter constrols the amount of processors used, it is advisible to investigate the speedup gained, when fitting and predicting, using different values for the parameter n_jobs. 